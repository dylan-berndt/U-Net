{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional vs. Dense Network\n",
    "\n",
    "The purpose of this code is to compare two approaches to semantic segmentation neural networks, those being a convolutional neural network similar to a U-Net, and a densely connected network of our design.\n",
    "\n",
    "Running the full notebook will train the densely connected network, display several of the model's predictions, and generate GIFs of the test dataset.\n",
    "\n",
    "If you want the convolutional model to be trained and evaluated, there are only a few code blocks (specified below) that shouldn't be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "# Seed randomizers\n",
    "tf.random.set_seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "labels = loadLabels('CamVid/')\n",
    "\n",
    "imageSize = (320, 256)\n",
    "\n",
    "trainSamples = 369\n",
    "testSamples = 20\n",
    "imagesPerBatch = 5\n",
    "# Defines the size of the tiles the densely connected model uses\n",
    "poolSize = 4\n",
    "\n",
    "train_x, train_y = loadDataset('CamVid/', 'train', trainSamples, labels, imageSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network\n",
    "\n",
    "This code defines the convolutional network.\n",
    "\n",
    "uNetDepth specifies the amount of downsamples the model will perform\n",
    "\n",
    "kernelSize specifies the size of the convolutional window\n",
    "\n",
    "filters controls the amount of convolutional filters the original convolutional block will have (Note: increasing this will very quickly increase the amount of training parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uNetDepth = 5\n",
    "kernelSize = 3\n",
    "filters = 4\n",
    "model = createUNet([imageSize[1], imageSize[0], 3], kernelSize, uNetDepth, filters, len(labels))\n",
    "batchSize = imagesPerBatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Network\n",
    "\n",
    "Run the below block only if you intend to train the densely connected network as opposed to the convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createDenseNet([poolSize, poolSize, 3], len(labels))\n",
    "\n",
    "train_x = tileImages(train_x, poolSize)\n",
    "train_y = tileImages(train_y, poolSize)\n",
    "\n",
    "batchSize = imagesPerBatch * int(train_x.shape[0] / trainSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=batchSize, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Delete training dataset to free memory\n",
    "del train_x, train_y\n",
    "test_x, test_y = loadDataset('CamVid/', 'test', testSamples, labels, imageSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below block only if you trained the dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = tileImages(test_x, poolSize)\n",
    "test_y = tileImages(test_y, poolSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = model.evaluate(test_x, test_y, batch_size=int(batchSize), verbose=2)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "batchSize = 5 * int(test_x.shape[0] / testSamples)\n",
    "predictions = model.predict(test_x, batch_size=int(batchSize / testSamples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below block only if you trained the dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = undoTiling(test_x, imageSize)\n",
    "test_y = undoTiling(test_y, imageSize, 32)\n",
    "predictions = undoTiling(predictions, imageSize, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = np.array([label[1] for label in labels])\n",
    "\n",
    "def colorizeImage(image):\n",
    "    return colors[np.argmax(image, axis=2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Visualization\n",
    "\n",
    "This block displays several images from the test dataset and their corresponding ground truth, along with the models prediction\n",
    "\n",
    "Change totalCheck to change the amount of samples visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "totalCheck = 10\n",
    "\n",
    "fig = plt.figure(figsize=(18, 6 * totalCheck))\n",
    "for checkNum in range(totalCheck):\n",
    "    predictionToShow = predictions[checkNum]\n",
    "    groundTruth = test_y[checkNum]\n",
    "    \n",
    "    originalImage = test_x[checkNum]\n",
    "    groundImage = (colorizeImage(groundTruth) / 255.0 + originalImage) * 0.5\n",
    "    predictionImage = (colorizeImage(predictionToShow) / 255.0 + originalImage) * 0.5\n",
    "\n",
    "    fig.add_subplot(totalCheck, 3, checkNum * 3 + 1) \n",
    "    plt.axis('off')\n",
    "    if not checkNum:\n",
    "        plt.title(\"Original\")\n",
    "    plt.imshow(originalImage, interpolation='nearest')\n",
    "    \n",
    "    fig.add_subplot(totalCheck, 3, checkNum * 3 + 2) \n",
    "    plt.axis('off')\n",
    "    if not checkNum:\n",
    "        plt.title(\"Ground Truth\")\n",
    "    plt.imshow(groundImage, interpolation='nearest')\n",
    "    \n",
    "    fig.add_subplot(totalCheck, 3, checkNum * 3 + 3)\n",
    "    plt.axis('off')\n",
    "    if not checkNum:\n",
    "        plt.title(\"Prediction\")\n",
    "    plt.imshow(predictionImage, interpolation='nearest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model with the date it was trained\n",
    "from datetime import datetime\n",
    "dateString = datetime.now().strftime(\"%m.%d.%Y.%H\")\n",
    "\n",
    "model.save(\"Trained/trained \" + dateString + \".keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate GIFS\n",
    "The below code loads in a trained model, performs predictions on the test set, and compiles the video data into a GIF.\n",
    "\n",
    "Does not need to be run for testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "model = tf.keras.models.load_model(\"Trained/trained 04.22.2024.14 convolutional.keras\")\n",
    "labels = loadLabels('CamVid/')\n",
    "imageSize = [320, 256]\n",
    "test_x, test_y = loadDataset('CamVid/', 'test', 232, labels, imageSize, shuffle=False)\n",
    "\n",
    "# test_x = tileImages(test_x, 4)\n",
    "\n",
    "predictions = model.predict(test_x, batch_size=int(test_x.shape[0] / 232))\n",
    "\n",
    "# test_x = undoTiling(test_x, imageSize)\n",
    "# predictions = undoTiling(predictions, imageSize, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalImg = []\n",
    "groundTruth = []\n",
    "predictImgs = []\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    imageData = (test_x[i] * 255).astype(np.uint8)\n",
    "    image = Image.fromarray(imageData)\n",
    "    groundImage = Image.fromarray(((colorizeImage(test_y[i]) + imageData) / 2).astype(np.uint8))\n",
    "    predictionImage = Image.fromarray(((colorizeImage(predictions[i]) + imageData) / 2).astype(np.uint8))\n",
    "    print(i, end='\\r')\n",
    "\n",
    "    originalImg.append(image)\n",
    "    groundTruth.append(groundImage)\n",
    "    predictImgs.append(predictionImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalImg[0].save(\"OriginalImg.gif\", save_all=True, append_images=originalImg[1:])\n",
    "groundTruth[0].save(\"GroundTruth.gif\", save_all=True, append_images=groundTruth[1:])\n",
    "predictImgs[0].save(\"Predictions.gif\", save_all=True, append_images=predictImgs[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
