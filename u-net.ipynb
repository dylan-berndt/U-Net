{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional vs. Dense Network\n",
    "\n",
    "The purpose of this code is to compare two approaches to semantic segmentation neural networks, those being a convolutional neural network similar to a U-Net, and a densely connected network of our design.\n",
    "\n",
    "Running the full notebook will train the model type that is specified by modelType below, show some basic visualizations of the predictions, and save the predicted video data.\n",
    "\n",
    "This block should always be run before anything else to seed random number generators, load the utils script, load the dataset labels, and define imageSize and other important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "# Seed randomizers\n",
    "tf.random.set_seed(1234)\n",
    "random.seed(1234)\n",
    "\n",
    "labels = loadLabels('CamVid/')\n",
    "\n",
    "imageSize = (320, 256)\n",
    "\n",
    "trainSamples = 369\n",
    "testSamples = 20\n",
    "imagesPerBatch = 5\n",
    "# Defines the size of the tiles the densely connected model uses\n",
    "poolSize = 32\n",
    "\n",
    "\n",
    "# Choose from \"dense\" or \"convolutional\"\n",
    "modelType = \"convolutional\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_x, train_y = loadDataset('CamVid/', 'train', trainSamples, labels, imageSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network\n",
    "\n",
    "This code defines the convolutional network.\n",
    "\n",
    "uNetDepth specifies the amount of downsamples the model will perform\n",
    "\n",
    "kernelSize specifies the size of the convolutional window\n",
    "\n",
    "filters controls the amount of convolutional filters the original convolutional block will have (Note: increasing this will very quickly increase the amount of training parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uNetDepth = 5\n",
    "kernelSize = 3\n",
    "filters = 4\n",
    "model = createUNet([imageSize[1], imageSize[0], 3], kernelSize, uNetDepth, filters, len(labels))\n",
    "batchSize = imagesPerBatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Network\n",
    "\n",
    "This block will only run if the dense model is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelType == \"dense\":\n",
    "    model = createDenseNet([poolSize, poolSize, 3], len(labels))\n",
    "    \n",
    "    train_x = tileImages(train_x, poolSize)\n",
    "    train_y = tileImages(train_y, poolSize)\n",
    "    \n",
    "    batchSize = imagesPerBatch * int(train_x.shape[0] / trainSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=batchSize, epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete training dataset to free memory\n",
    "del train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model with the date it was trained\n",
    "from datetime import datetime\n",
    "dateString = datetime.now().strftime(\"%m.%d.%Y.%H\")\n",
    "\n",
    "model.save(\"Trained/trained \" + dateString + \".keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Perform Visualization\n",
    "\n",
    "Running the code underneath this block will prompt the user to select a trained model (Found in the Trained folder) to run visualization on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter.filedialog import askopenfilename\n",
    "from tkinter import Tk\n",
    "\n",
    "root = Tk()\n",
    "root.iconify()\n",
    "\n",
    "fileName = askopenfilename(parent=root, title=\"Select trained model file\", filetypes=[(\"Model files\", \"*.keras\")])\n",
    "\n",
    "root.destroy()\n",
    "\n",
    "model = tf.keras.models.load_model(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_x, test_y = loadDataset('CamVid/', 'test', testSamples, labels, imageSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block will only run if the dense model is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelType == \"dense\":\n",
    "    test_x = tileImages(test_x, poolSize)\n",
    "    test_y = tileImages(test_y, poolSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "batchSize = 5 * int(test_x.shape[0] / testSamples)\n",
    "predictions = model.predict(test_x, batch_size=int(batchSize / testSamples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block will only run if the dense model is selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelType == \"dense\":\n",
    "    test_x = undoTiling(test_x, imageSize)\n",
    "    test_y = undoTiling(test_y, imageSize, 32)\n",
    "    predictions = undoTiling(predictions, imageSize, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = np.array([label[1] for label in labels])\n",
    "\n",
    "def colorizeImage(image):\n",
    "    return colors[np.argmax(image, axis=2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Visualization\n",
    "\n",
    "This block displays several images from the test dataset and their corresponding ground truth, along with the models prediction\n",
    "\n",
    "Change totalCheck to change the amount of samples visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "totalCheck = 10\n",
    "\n",
    "fig = plt.figure(figsize=(18, 6 * totalCheck))\n",
    "for checkNum in range(totalCheck):\n",
    "    predictionToShow = predictions[checkNum]\n",
    "    groundTruth = test_y[checkNum]\n",
    "    \n",
    "    originalImage = test_x[checkNum]\n",
    "    groundImage = (colorizeImage(groundTruth) / 255.0 + originalImage) * 0.5\n",
    "    predictionImage = (colorizeImage(predictionToShow) / 255.0 + originalImage) * 0.5\n",
    "\n",
    "    fig.add_subplot(totalCheck, 3, checkNum * 3 + 1) \n",
    "    plt.axis('off')\n",
    "    if not checkNum:\n",
    "        plt.title(\"Original\")\n",
    "    plt.imshow(originalImage, interpolation='nearest')\n",
    "    \n",
    "    fig.add_subplot(totalCheck, 3, checkNum * 3 + 2) \n",
    "    plt.axis('off')\n",
    "    if not checkNum:\n",
    "        plt.title(\"Ground Truth\")\n",
    "    plt.imshow(groundImage, interpolation='nearest')\n",
    "    \n",
    "    fig.add_subplot(totalCheck, 3, checkNum * 3 + 3)\n",
    "    plt.axis('off')\n",
    "    if not checkNum:\n",
    "        plt.title(\"Prediction\")\n",
    "    plt.imshow(predictionImage, interpolation='nearest')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate GIFS\n",
    "The below code loads in a trained model, performs predictions on the test set, and compiles the video data into a GIF.\n",
    "\n",
    "Does not need to be run for testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = loadLabels('CamVid/')\n",
    "imageSize = [320, 256]\n",
    "test_x, test_y = loadDataset('CamVid/', 'test', 232, labels, imageSize, shuffle=False)\n",
    "\n",
    "\n",
    "modelType = \"dense\"\n",
    "\n",
    "\n",
    "if modelType == \"dense\":\n",
    "    test_x = tileImages(test_x, poolSize)\n",
    "\n",
    "predictions = model.predict(test_x, batch_size=int(test_x.shape[0] / 232))\n",
    "\n",
    "if modelType == \"dense\":\n",
    "    test_x = undoTiling(test_x, imageSize)\n",
    "    predictions = undoTiling(predictions, imageSize, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalImg = []\n",
    "groundTruth = []\n",
    "predictImgs = []\n",
    "\n",
    "for i in range(len(test_x)):\n",
    "    imageData = (test_x[i] * 255).astype(np.uint8)\n",
    "    image = Image.fromarray(imageData)\n",
    "    groundImage = Image.fromarray(((colorizeImage(test_y[i]) + imageData) / 2).astype(np.uint8))\n",
    "    predictionImage = Image.fromarray(((colorizeImage(predictions[i]) + imageData) / 2).astype(np.uint8))\n",
    "    print(i, end='\\r')\n",
    "\n",
    "    originalImg.append(image)\n",
    "    groundTruth.append(groundImage)\n",
    "    predictImgs.append(predictionImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalImg[0].save(\"OriginalImg.gif\", save_all=True, append_images=originalImg[1:])\n",
    "groundTruth[0].save(\"GroundTruth.gif\", save_all=True, append_images=groundTruth[1:])\n",
    "predictImgs[0].save(\"Predictions.gif\", save_all=True, append_images=predictImgs[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
